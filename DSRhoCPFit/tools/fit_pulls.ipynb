{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\n",
    "sns.set_style({\"axes.grid\": \"True\", \"grid.color\": \"0.95\"})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def darken_color(color, p):\n",
    "    return (color[0]*p,color[1]*p,color[2]*p)\n",
    "\n",
    "colors = sns.color_palette(\"muted\") + [(.1, .1, .1)]\n",
    "for code, color in zip([\"bd\",\"gd\",\"rd\",\"md\",\"yd\",\"cd\",\"kd\"], colors):\n",
    "    rgb = mpl.colors.colorConverter.to_rgb(darken_color(color,0.8))\n",
    "    mpl.colors.colorConverter.colors[code] = rgb\n",
    "    mpl.colors.colorConverter.cache[code] = rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare variable list for reading the result files. `time_dependent` needs to be changed to `False` for time-independent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dependent = True\n",
    "\n",
    "var_types = (\"gen\", \"fit\", \"err\")\n",
    "var_dict_ti = OrderedDict([\n",
    "            (\"ap\", r\"$|A_\\parallel|$\"), \n",
    "            (\"apa\", r\"$\\arg(A_\\parallel)$\"), \n",
    "            (\"a0\", r\"$|A_0|$\"), \n",
    "            (\"a0a\", r\"$\\arg(A_0)$\"), \n",
    "            (\"at\", r\"$|A_\\perp|$\"), \n",
    "            (\"ata\", r\"$\\arg(A_\\perp)$\")\n",
    "            ])\n",
    "\n",
    "var_dict_td = OrderedDict([\n",
    "            (\"ap\", r\"$|A_\\parallel|$\"), \n",
    "            (\"apa\", r\"$\\arg(A_\\parallel)$\"), \n",
    "            (\"a0\", r\"$|A_0|$\"), \n",
    "            (\"a0a\", r\"$\\arg(A_0)$\"), \n",
    "            (\"at\", r\"$|A_\\perp|$\"), \n",
    "            (\"ata\", r\"$\\arg(A_\\perp)$\"),\n",
    "            (\"xp\", r\"$x_\\parallel$\"),\n",
    "            (\"x0\", r\"$x_0$\"),\n",
    "            (\"xt\", r\"$x_\\perp$\"),\n",
    "            (\"yp\", r\"$y_\\parallel$\"),\n",
    "            (\"y0\", r\"$y_0$\"),\n",
    "            (\"yt\", r\"$y_\\perp$\"),\n",
    "            (\"xbp\", r\"$\\bar x_\\parallel$\"),\n",
    "            (\"xb0\", r\"$\\bar x_0$\"),\n",
    "            (\"xbt\", r\"$\\bar x_\\perp$\"),\n",
    "            (\"ybp\", r\"$\\bar y_\\parallel$\"),\n",
    "            (\"yb0\", r\"$\\bar y_0$\"),\n",
    "            (\"ybt\", r\"$\\bar y_\\perp$\")\n",
    "            ])\n",
    "\n",
    "var_dict = {}\n",
    "if time_dependent:\n",
    "    var_dict = var_dict_td\n",
    "else:\n",
    "    var_dict = var_dict_ti\n",
    "\n",
    "var_names = list(var_dict.keys())\n",
    "vars = ([var_name + \"_\" + var_type for var_name in var_names for var_type in var_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "dirs_ti = [\n",
    "    '../results/Kpi_ti_CR',\n",
    "    '../results/Kpipi0_ti_CR',\n",
    "    '../results/K3pi_ti_CR',\n",
    "    '../results/together_ti_CR',\n",
    "    '../results/Kpi_ti_CRSCF',\n",
    "    '../results/Kpipi0_ti_CRSCF',\n",
    "    '../results/K3pi_ti_CRSCF',\n",
    "    '../results/together_ti_CRSCF',\n",
    "    '../results/Kpi_ti_all',\n",
    "    '../results/Kpipi0_ti_all',\n",
    "    '../results/K3pi_ti_all',\n",
    "    '../results/together_ti_all'\n",
    "]\n",
    "\n",
    "dirs_td = [\n",
    "    '../results/Kpi_td_CR',\n",
    "    '../results/Kpipi0_td_CR',\n",
    "    '../results/K3pi_td_CR',\n",
    "    '../results/together_td_CR',\n",
    "    '../results/Kpi_td_CRSCF',\n",
    "    '../results/Kpipi0_td_CRSCF',\n",
    "    '../results/K3pi_td_CRSCF',\n",
    "    '../results/together_td_CRSCF',\n",
    "    '../results/Kpi_td_all',\n",
    "    '../results/Kpipi0_td_all',\n",
    "    '../results/K3pi_td_all',\n",
    "    '../results/together_td_all'\n",
    "]\n",
    "\n",
    "dirs = []\n",
    "if (time_dependent):\n",
    "    dirs = dirs_td\n",
    "else:\n",
    "    dirs = dirs_ti \n",
    "\n",
    "dfs = []\n",
    "for directory in dirs:\n",
    "    all_files = glob.glob(os.path.join(directory, \"stream*[0-9]\"))\n",
    "    print(\"Num files in '\" + str(directory) + \"': \" + str(len(all_files)))\n",
    "    df_from_each_file = (pd.read_csv(f, sep=\" \\|\\| | \\| | \", header=None, names=vars, engine='python') for f in all_files)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the pulls and display their means and then standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pulls = []\n",
    "for i in range(0, len(dirs)):\n",
    "    df = dfs[i]\n",
    "    df_pulls_dict = {var : (df[var + \"_fit\"] - df[var + \"_gen\"])/df[var + \"_err\"] for var in var_names}\n",
    "    df_pulls = pd.DataFrame(df_pulls_dict)\n",
    "    dfs_pulls.append(df_pulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_names:\n",
    "    print(\"{:4}| \".format(var), end='')\n",
    "    for i in range(0, len(dirs)):\n",
    "        print(\"{:+5.2f} | \".format(dfs_pulls[i].mean()[var]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_names:\n",
    "    print(\"{:4}| \".format(var), end='')\n",
    "    for i in range(0, len(dirs)):\n",
    "        print(\"{:+5.2f} | \".format(dfs_pulls[i].std()[var]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows a distribution of pulls for all directories and all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 0\n",
    "if time_dependent:\n",
    "    rows = 6\n",
    "else:\n",
    "    rows = 2\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [9, rows * 3]\n",
    "for i, dir in enumerate(dirs):\n",
    "    axs = dfs_pulls[i].hist(column=list(var_names),\n",
    "                            sharey=True, layout=(rows, 3), range=(-5, 5), bins=10)\n",
    "    print(\"Plots for dir \" + os.path.basename(dir))\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel(var_dict[ax.title.get_text()])\n",
    "        if ax.title.get_text() == \"a0a\":\n",
    "            ax.text(0.5, 0.5, \"Empty on purpose\", horizontalalignment=\"center\", \n",
    "                    verticalalignment=\"center\", transform=ax.transAxes)\n",
    "        ax.set_title(\"\")\n",
    "        \n",
    "    plt.savefig(os.path.basename(dir) + \"_pull_dist.pdf\", bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, exog=None, **kwds):\n",
    "        #if exog is None:\n",
    "        #    exog = np.zeros_like(endog)\n",
    "            \n",
    "        super(Gaussian, self).__init__(endog, exog, **kwds)\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        loc = params[0]\n",
    "        scale = params[1]\n",
    "\n",
    "        return -np.log(norm.pdf(self.endog, loc=loc, scale=scale))\n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n",
    "        if start_params is None:\n",
    "            loc_start = self.endog.mean()\n",
    "            scale_start = self.endog.std()\n",
    "            \n",
    "            start_params = np.array([loc_start, scale_start])\n",
    "            \n",
    "        return super(Gaussian, self).fit(start_params=start_params,\n",
    "                                         maxiter=maxiter, maxfun=maxfun, **kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fits the pull distributions with Gaussians and shows the uncertainties on the $\\mu$ and $\\sigma$ of each distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vars = list(var_names)\n",
    "real_vars.remove('a0a')\n",
    "\n",
    "for i, dir in enumerate(dirs):\n",
    "    print(\"Results for dir \" + dir)\n",
    "    for var in real_vars:\n",
    "        model = Gaussian(dfs_pulls[i][var]);\n",
    "        results = model.fit(disp=False);\n",
    "        print(\"{:4}: ({:+.2f} +- {:.2f}) +- ({:+.2f} +- {:.2f})\".format(\n",
    "            var, results.params[0], results.bse[0], results.params[1], results.bse[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the relative errors $|\\sigma/\\mu|$ for each variable and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative errors\n",
    "dfs_relative_errors = []\n",
    "for i in range(0, len(dirs)):\n",
    "    df = dfs[i]\n",
    "    df_relative_errors_dict = {var : abs(df[var + \"_err\"]/df[var + \"_fit\"]) for var in var_names}\n",
    "    df_relative_errors = pd.DataFrame(df_relative_errors_dict)\n",
    "    dfs_relative_errors.append(df_relative_errors)\n",
    "#df_pulls = df_pulls.drop(list(var_names[0:6]), axis=1)\n",
    "\n",
    "# Display relative errors in a table\n",
    "for var in var_names:\n",
    "    print(\"{:4}| \".format(var), end='')\n",
    "    for i, dir in enumerate(dirs):\n",
    "        print(\"{:6.2f} | \".format(dfs_relative_errors[i].mean()[var]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be useful if we want to plot the fitted Gaussian on top of the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"$\\\\tau$ [ps]\")\n",
    "#ax.set_xlim(1.5, 1.57)\n",
    "\n",
    "data = dfs_pulls[0].apa\n",
    "\n",
    "# Create histogram and calculate area under it for\n",
    "# renormalization of fitted PDF\n",
    "n, bins, patches = plt.hist(data, bins=20, edgecolor=darken_color(sns.color_palette(\"muted\")[0], 0.8))\n",
    "area = np.sum(np.diff(bins)*n)\n",
    "\n",
    "mu, sigma = norm.fit(data)\n",
    "\n",
    "# Create a bunch of equidistant points to calculate the \n",
    "# function values at (many points to make it look smooth)\n",
    "x = np.linspace(data.min(), data.max(), 100)\n",
    "norm_fitted = norm.pdf(x, mu, sigma)*area\n",
    "plt.plot(x, norm_fitted)\n",
    "print(\"tau = {:.3f} +- {:.3f} ps\".format(mu, sigma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
